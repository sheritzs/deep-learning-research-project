{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZhflu2xvaza"
      },
      "source": [
        "# Hyperparameter Tuning with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG9HTBLZNmVu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "import os\n",
        "\n",
        "# change current working directory\n",
        "os.chdir('/content/gdrive/My Drive/MRP/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "y7SCQB-0NXVM"
      },
      "outputs": [],
      "source": [
        "!pip install -U optuna\n",
        "!pip install optuna-integration\n",
        "!pip install 'u8darts[all]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXxOl-SbX8xY"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\"\n",
        ")\n",
        "\n",
        "import logging\n",
        "logging.disable(logging.CRITICAL)\n",
        "\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from project_code import processing_functions as pf\n",
        "import time\n",
        "\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "from darts.metrics import mae, rmse\n",
        "from darts.models import (BlockRNNModel, ExponentialSmoothing, LightGBMModel, NBEATSModel, XGBModel)\n",
        "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOHT1nfYNmgT"
      },
      "outputs": [],
      "source": [
        "file_path_models = 'models/'\n",
        "data_file = 'data/bbm_data_incl_outliers.csv'\n",
        "hyperparam_file = f'{file_path_models}optuna_results.json'\n",
        "\n",
        "bbm_data = pd.read_csv(data_file, index_col='date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_GK3BHBNm98"
      },
      "outputs": [],
      "source": [
        "target = pf.create_timeseries(bbm_data, 'sunshine_hr')\n",
        "\n",
        "# create past covariates as stacked timeseries of exogenous variables\n",
        "past_covariates = pf.get_covariate_ts(bbm_data)\n",
        "\n",
        "# create training and validation datasets\n",
        "# Save 2023 data for testing, use 1994 to 2021 for training, and 2022 for validation\n",
        "training_cutoff = pd.Timestamp(year=2022, month=12, day=31)\n",
        "validation_cutoff = pd.Timestamp(year=2021, month=12, day=31)\n",
        "\n",
        "target_train, _ = target.split_after(training_cutoff) # test data will not be used in this notebook (see mrp_experiments.ipynb)\n",
        "target_train, target_val = target_train.split_after(validation_cutoff)\n",
        "\n",
        "covariates_train, _ = past_covariates.split_after(training_cutoff)\n",
        "covariates_train, _ = covariates_train.split_after(validation_cutoff) # train/val split does not  need to be explicitly created; Darts matches up the required time slices\n",
        "\n",
        "covariate_scaler = Scaler()\n",
        "covariate_scaler.fit(covariates_train)\n",
        "past_covariates_trf = covariate_scaler.transform(past_covariates) #scale based on training data to avoid information leakage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzr994ZO2gAK"
      },
      "source": [
        "# Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ5kp86t8Zxm"
      },
      "source": [
        "## GPU Details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmfD3yPR8fTG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n70WzRq80Gtz"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "N_TRIALS = 100\n",
        "MAX_NUM_EPOCHS = 150\n",
        "FORECAST_HORIZONS = (1, 3, 7, 14, 28)\n",
        "INPUT_CHUNK_LENGTHS = [x*2 for x in FORECAST_HORIZONS]\n",
        "LAGS = list(np.unique([2*x if x < 28 else x for x in FORECAST_HORIZONS]))\n",
        "\n",
        "all_results = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTb47Boc_6Y-"
      },
      "source": [
        "**Note:** This notebook is intended and structured for a single run; however, in practice, there were several interruptions due to Colab runtime disconnections, which necessitated reading in the most current results file to continue from, as well as revising certain key lines as appropriate (e.g. *for fh in FORECAST_HORIZONS[2:]:*)  The following code can be used for such cases, and references to *all_results* can be updated to *current_results*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DweCS5Um21xa"
      },
      "outputs": [],
      "source": [
        "# current_results = pf.read_json_file(file=hyperparam_file, output_type='dict')\n",
        "# current_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIXctCa5p14K"
      },
      "source": [
        "## N-BEATS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdxiBBBqUjcg"
      },
      "outputs": [],
      "source": [
        "version = 'generic'\n",
        "\n",
        "for fh in FORECAST_HORIZONS:\n",
        "\n",
        "    model_name = f'optuna_nbeats_{version}_fh{fh}'\n",
        "\n",
        "    print(f'\\nRunning Experiment for {model_name}...\\n')\n",
        "\n",
        "    def objective_nbeats(trial):\n",
        "        \"\"\"Hyperparameter search objective\"\"\"\n",
        "        torch.manual_seed(SEED)\n",
        "\n",
        "        pruner = pf.PyTorchLightningPruningCallback(trial,\n",
        "                                                    monitor='val_loss')\n",
        "        early_stopper = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            min_delta=0.001, # min change required to qualify as an improvement\n",
        "            patience=10, # num validation epochs w/ no improvement before training is stopped\n",
        "            verbose=True,\n",
        "            mode='min'\n",
        "        )\n",
        "\n",
        "        callbacks = [pruner, early_stopper]\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            pl_trainer_kwargs = {\n",
        "                'accelerator': 'gpu',\n",
        "                'callbacks': callbacks,\n",
        "            }\n",
        "        else:\n",
        "            pl_trainer_kwargs = {'callbacks': callbacks}\n",
        "\n",
        "        input_chunk_length = trial.suggest_categorical('input_chunk_length', INPUT_CHUNK_LENGTHS)\n",
        "        num_stacks =  trial.suggest_categorical('num_stacks', [10, 20, 30]) # only used in model if generic_architecture is set to True\n",
        "        num_blocks = trial.suggest_categorical('num_blocks', [1, 2, 3])\n",
        "        num_layers  = trial.suggest_categorical('num_layers', [3, 4, 5])\n",
        "        layer_widths = trial.suggest_categorical('layer_widths', [256, 512])\n",
        "        dropout = trial.suggest_float('dropout', 0, 0.4)\n",
        "        activation = trial.suggest_categorical('activation', ['ReLU', 'LeakyReLU'])\n",
        "        learning_rate = trial.suggest_float(\"lr\",  1e-5, 1e-1, log=True)\n",
        "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
        "\n",
        "\n",
        "        model = NBEATSModel(\n",
        "                            random_state=1,\n",
        "                            input_chunk_length=input_chunk_length,\n",
        "                            output_chunk_length=fh,\n",
        "                            num_stacks=num_stacks,\n",
        "                            num_blocks=num_blocks,\n",
        "                            num_layers=num_layers,\n",
        "                            layer_widths=layer_widths,\n",
        "                            dropout=dropout,\n",
        "                            activation=activation,\n",
        "                            batch_size=batch_size,\n",
        "                            n_epochs=MAX_NUM_EPOCHS,\n",
        "                            generic_architecture=True if version == 'generic' else False,\n",
        "                            pl_trainer_kwargs=pl_trainer_kwargs,\n",
        "                            optimizer_kwargs={'lr': learning_rate},\n",
        "                            log_tensorboard=True,\n",
        "                            model_name = f'{model_name}_{datetime.datetime.now().strftime((\"%Y%m%d-%H%M%S\"))}',\n",
        "                            save_checkpoints=True,\n",
        "                            force_reset=True,\n",
        "                        )\n",
        "\n",
        "        model.fit(\n",
        "                series=target_train,\n",
        "                past_covariates=past_covariates, #N-BEATS does not require scaling\n",
        "                val_series=target_val,\n",
        "                val_past_covariates=past_covariates\n",
        "                )\n",
        "\n",
        "        y_pred = model.predict(n=fh)\n",
        "        rmse_result = rmse(y_pred, target_val[:fh])\n",
        "\n",
        "        return rmse_result\n",
        "\n",
        "    hyp_search_results = pf.hyperparameter_search(objective_nbeats, n_trials=N_TRIALS, model_name=model_name)\n",
        "    best_num_epochs = pf.get_best_num_epochs(model_name)\n",
        "    hyp_search_results[model_name]['best_parameters']['n_epochs'] = best_num_epochs\n",
        "    all_results.update(hyp_search_results)\n",
        "    # current_results.update(hyp_search_results)\n",
        "    pf.post_results(all_results, hyperparam_file, 'w')\n",
        "    # pf.post_results(current_results, hyperparam_file, 'w')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60GP2AJ8x78D"
      },
      "outputs": [],
      "source": [
        "# display(all_results)\n",
        "# display(current_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wn4TuVU5fuj"
      },
      "source": [
        "## LSTM and GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz6HfpPjyjZt"
      },
      "outputs": [],
      "source": [
        "for version in ['LSTM', 'GRU']:\n",
        "\n",
        "    for fh in FORECAST_HORIZONS:\n",
        "\n",
        "        model_name = f'optuna_{version.lower()}_fh{fh}'\n",
        "        print(f'\\nRunning Experiment for {model_name}...\\n')\n",
        "\n",
        "        def objective_rnn(trial):\n",
        "            \"\"\"Hyperparameter search objective\"\"\"\n",
        "\n",
        "            torch.manual_seed(SEED)\n",
        "\n",
        "            pruner = pf.PyTorchLightningPruningCallback(trial,\n",
        "                                                        monitor='val_loss')\n",
        "            early_stopper = EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                min_delta=0.001, # min change required to qualify as an improvement\n",
        "                patience=10, # num validation epochs w/ no improvement before training is stopped\n",
        "                verbose=True,\n",
        "                mode='min'\n",
        "            )\n",
        "\n",
        "            callbacks = [pruner, early_stopper]\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                pl_trainer_kwargs = {\n",
        "                    'accelerator': 'gpu',\n",
        "                    'callbacks': callbacks,\n",
        "                }\n",
        "            else:\n",
        "                pl_trainer_kwargs = {'callbacks': callbacks}\n",
        "\n",
        "\n",
        "            input_chunk_length = trial.suggest_categorical('input_chunk_length', INPUT_CHUNK_LENGTHS)\n",
        "            batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
        "            hidden_dim = trial.suggest_int('hidden_dim', 15, 40)\n",
        "            n_rnn_layers = trial.suggest_int('n_rnn_layers', 2, 5)\n",
        "            dropout = trial.suggest_float('dropout', 0, 0.4)\n",
        "            learning_rate = trial.suggest_float('lr',  1e-5, 1e-1, log=True)\n",
        "\n",
        "\n",
        "            model = BlockRNNModel(\n",
        "                        random_state=1,\n",
        "                        input_chunk_length=input_chunk_length,\n",
        "                        output_chunk_length=fh,\n",
        "                        model=version,\n",
        "                        hidden_dim=hidden_dim,\n",
        "                        n_rnn_layers=n_rnn_layers,\n",
        "                        batch_size=batch_size,\n",
        "                        n_epochs=MAX_NUM_EPOCHS,\n",
        "                        dropout=dropout,\n",
        "                        pl_trainer_kwargs=pl_trainer_kwargs,\n",
        "                        optimizer_kwargs = {'lr': learning_rate},\n",
        "                        log_tensorboard=True,\n",
        "                        model_name=f'{model_name}_{datetime.datetime.now().strftime((\"%Y%m%d-%H%M%S\"))}',\n",
        "                        save_checkpoints=True,\n",
        "                        force_reset=True,\n",
        "                )\n",
        "\n",
        "            model.fit(\n",
        "                    series=target_train,\n",
        "                    past_covariates=past_covariates_trf,\n",
        "                    val_series=target_val,\n",
        "                    val_past_covariates=past_covariates_trf\n",
        "                    )\n",
        "\n",
        "            y_pred = model.predict(n=fh)\n",
        "            rmse_result = rmse(y_pred, target_val[:fh])\n",
        "\n",
        "            return rmse_result\n",
        "\n",
        "        hyp_search_results = pf.hyperparameter_search(objective_rnn, n_trials=N_TRIALS, model_name=model_name)\n",
        "        best_num_epochs = pf.get_best_num_epochs(model_name)\n",
        "        hyp_search_results[model_name]['best_parameters']['n_epochs'] = best_num_epochs\n",
        "        all_results.update(hyp_search_results)\n",
        "        # current_results.update(hyp_search_results)\n",
        "        pf.post_results(all_results, hyperparam_file, 'w')\n",
        "        # pf.post_results(current_results, hyperparam_file, 'w')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TJeMoxsjoul"
      },
      "outputs": [],
      "source": [
        "# display(all_results)\n",
        "# display(current_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGCzbVyWlCj8"
      },
      "source": [
        "## XGBoost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC1wSW7oyrTt"
      },
      "outputs": [],
      "source": [
        "np.random.seed(SEED)\n",
        "\n",
        "for fh in FORECAST_HORIZONS:\n",
        "\n",
        "    model_name = f'optuna_xgboost_fh{fh}'\n",
        "    print(f'\\nRunning Experiment for {model_name}...\\n')\n",
        "\n",
        "    def objective_xgb(trial):\n",
        "        \"\"\"Hyper parameter search objective\"\"\"\n",
        "\n",
        "        # hyperparameter space\n",
        "        lags = trial.suggest_categorical('lags', LAGS)\n",
        "        lags_past_covariates = trial.suggest_categorical('lags_past_covariates', LAGS)\n",
        "\n",
        "        model = XGBModel(lags=lags,\n",
        "                        lags_past_covariates=lags_past_covariates,\n",
        "                        output_chunk_length=fh)\n",
        "\n",
        "        model.fit(\n",
        "            series=target_train,\n",
        "            past_covariates=past_covariates_trf,\n",
        "            val_series=target_val,\n",
        "            val_past_covariates=past_covariates_trf,\n",
        "            verbose=False\n",
        "            )\n",
        "\n",
        "        y_pred = model.predict(n=fh)\n",
        "        rmse_result = rmse(y_pred, target_val[:fh])\n",
        "\n",
        "        return rmse_result\n",
        "\n",
        "    hyp_search_results = pf.hyperparameter_search(objective_xgb, n_trials=N_TRIALS, model_name=model_name)\n",
        "    all_results.update(hyp_search_results)\n",
        "    # current_results.update(hyp_search_results)\n",
        "    pf.post_results(all_results, hyperparam_file, 'w')\n",
        "    # pf.post_results(current_results, hyperparam_file, 'w')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSDiZ4z0gMt4"
      },
      "outputs": [],
      "source": [
        "# display(all_results)\n",
        "# display(current_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub0MJel3lG1V"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHE_vUKeyyey"
      },
      "outputs": [],
      "source": [
        "np.random.seed(SEED)\n",
        "\n",
        "for fh in FORECAST_HORIZONS:\n",
        "\n",
        "    model_name = f'optuna_lgbm_fh{fh}'\n",
        "    print(f'\\nRunning Experiment for {model_name}...\\n')\n",
        "\n",
        "    def objective_lgbm(trial):\n",
        "        \"\"\"Hyper parameter search objective\"\"\"\n",
        "\n",
        "        # hyperparameter space\n",
        "        lags = trial.suggest_categorical('lags', LAGS)\n",
        "        lags_past_covariates = trial.suggest_categorical('lags_past_covariates', LAGS)\n",
        "\n",
        "        model = LightGBMModel(lags=lags,\n",
        "                        lags_past_covariates=lags_past_covariates,\n",
        "                        output_chunk_length=fh,\n",
        "                        verbose=-1)\n",
        "\n",
        "        model.fit(\n",
        "            series=target_train,\n",
        "            past_covariates=past_covariates_trf,\n",
        "            val_series=target_val,\n",
        "            val_past_covariates=past_covariates_trf\n",
        "            )\n",
        "\n",
        "        y_pred = model.predict(n=fh)\n",
        "        rmse_result = rmse(y_pred, target_val[:fh])\n",
        "\n",
        "        return rmse_result\n",
        "\n",
        "    hyp_search_results = pf.hyperparameter_search(objective_lgbm, n_trials=N_TRIALS, model_name=model_name)\n",
        "    all_results.update(hyp_search_results)\n",
        "    # current_results.update(hyp_search_results)\n",
        "    pf.post_results(all_results, hyperparam_file, 'w')\n",
        "    # pf.post_results(current_results, hyperparam_file, 'w')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deIBtVgX6qcx"
      },
      "outputs": [],
      "source": [
        "# display(all_results)\n",
        "# display(current_results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP8n08RmPp8DT0qHgzjfPUz"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}